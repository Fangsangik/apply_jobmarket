#!/usr/bin/env python3
"""
Flask ê¸°ë°˜ ì±„ìš©ê³µê³  ë¶„ì„ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
ìµœì í™”ëœ DB ì¿¼ë¦¬ì™€ í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
"""

from flask import Flask, render_template, request, jsonify, session
import sys
import os
import pandas as pd
import json
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import plotly.utils
import re

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
src_path = os.path.join(current_dir, 'src', 'job_market_analyzer')
sys.path.insert(0, src_path)

try:
    from postgresql_job_curator import PostgreSQLJobCurator
except ImportError as e:
    print(f"ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print(f"í˜„ì¬ ê²½ë¡œ: {current_dir}")
    print(f"ì¶”ê°€ëœ ê²½ë¡œ: {src_path}")
    print(f"ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(src_path)}")
    sys.exit(1)

app = Flask(__name__)
app.secret_key = 'your-secret-key-here'

# ì „ì—­ ë³€ìˆ˜
curator = None

def initialize_curator():
    """PostgreSQL íë ˆì´í„° ì´ˆê¸°í™”"""
    global curator
    try:
        curator = PostgreSQLJobCurator()
        return True
    except Exception as e:
        print(f"PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def generate_visualization_data(data):
    """ì‹œê°í™”ìš© ë°ì´í„° ìƒì„±"""
    charts = {}
    
    try:
        # 1. ì›”ë³„ ì±„ìš©ê³µê³  ì¶”ì´ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
        from datetime import datetime, timedelta
        
        current_date = datetime.now()
        monthly_counts = {}
        
        # ì‹¤ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ created_at ê¸°ë°˜ìœ¼ë¡œ ì›”ë³„ ë¶„í¬ ê³„ì‚°
        if not data.empty and 'created_at' in data.columns:
            data_with_date = data[data['created_at'].notna()]
            if len(data_with_date) > 0:
                # created_atì„ datetimeìœ¼ë¡œ ë³€í™˜
                data_with_date = data_with_date.copy()
                data_with_date['created_at'] = pd.to_datetime(data_with_date['created_at'])
                data_with_date['month'] = data_with_date['created_at'].dt.strftime('%Y-%m')
                
                # ì›”ë³„ ì‹¤ì œ ê°œìˆ˜ ê³„ì‚°
                monthly_real = data_with_date['month'].value_counts().to_dict()
                
                # ìµœê·¼ 6ê°œì›”ë§Œ í‘œì‹œ
                for i in range(6):
                    month_date = current_date - timedelta(days=30*i)
                    month_key = month_date.strftime('%Y-%m')
                    monthly_counts[month_key] = monthly_real.get(month_key, 0)
            else:
                # created_at ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ë°ì´í„° ìˆ˜ë¥¼ í˜„ì¬ ë‹¬ì—ë§Œ í‘œì‹œ
                current_month = current_date.strftime('%Y-%m')
                monthly_counts[current_month] = len(data)
                
                # ë‚˜ë¨¸ì§€ ë‹¬ì€ 0ìœ¼ë¡œ ì„¤ì •
                for i in range(1, 6):
                    month_date = current_date - timedelta(days=30*i)
                    month_key = month_date.strftime('%Y-%m')
                    monthly_counts[month_key] = 0
        else:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ë°ì´í„° ìˆ˜ë¥¼ í˜„ì¬ ë‹¬ì—ë§Œ í‘œì‹œ
            current_month = current_date.strftime('%Y-%m')
            monthly_counts[current_month] = len(data) if not data.empty else 0
            
            # ë‚˜ë¨¸ì§€ ë‹¬ì€ 0ìœ¼ë¡œ ì„¤ì •  
            for i in range(1, 6):
                month_date = current_date - timedelta(days=30*i)
                month_key = month_date.strftime('%Y-%m')
                monthly_counts[month_key] = 0
        
        # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_months = sorted(monthly_counts.keys())
        months = sorted_months
        counts = [monthly_counts[month] for month in months]
        
        fig1 = go.Figure()
        fig1.add_trace(go.Scatter(
            x=months, 
            y=counts, 
            mode='lines+markers',
            marker=dict(size=10, color='#2563eb'),
            line=dict(width=4, color='#2563eb', shape='spline'),
            fill='tozeroy',
            fillcolor='rgba(37, 99, 235, 0.1)',
            name='ì±„ìš©ê³µê³  ìˆ˜'
        ))
        # ì›”ë³„ ì¶”ì´ ì´ ê°œìˆ˜ ê³„ì‚°
        monthly_total = sum(counts) if counts else 0
        
        fig1.update_layout(
            title=f'ì›”ë³„ ì±„ìš©ê³µê³  ì¶”ì´ (ì´ {monthly_total:,}ê°œ)', 
            height=300, 
            margin=dict(l=20, r=20, t=40, b=20),
            xaxis_title='ì›”',
            yaxis_title='ê³µê³  ìˆ˜',
            showlegend=False,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            xaxis=dict(showgrid=True, gridcolor='rgba(128,128,128,0.2)'),
            yaxis=dict(showgrid=True, gridcolor='rgba(128,128,128,0.2)')
        )
        charts['monthly_trend'] = json.loads(plotly.utils.PlotlyJSONEncoder().encode(fig1))
        
        # 2. ì§ë¬´ë³„ ë¶„í¬ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜, ì •ë¦¬ëœ ì¹´í…Œê³ ë¦¬)
        job_role_counts = {}
        
        if not data.empty and 'major_category' in data.columns:
            valid_major = data[data['major_category'].notna() & (data['major_category'] != '') & (data['major_category'] != 'null')]
            if len(valid_major) > 0:
                # major_category ë°ì´í„° ì •ë¦¬ (JSON ë°°ì—´ í˜•íƒœ íŒŒì‹±)
                clean_categories = {}
                for category_raw in valid_major['major_category']:
                    try:
                        if isinstance(category_raw, str):
                            # JSON ë°°ì—´ í˜•íƒœ íŒŒì‹±: ["ë°±ì—”ë“œ"] -> ë°±ì—”ë“œ
                            if category_raw.startswith('[') and category_raw.endswith(']'):
                                import ast
                                categories = ast.literal_eval(category_raw)
                                if categories and len(categories) > 0:
                                    main_category = categories[0]  # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©
                                    if main_category and main_category.strip():
                                        clean_categories[main_category] = clean_categories.get(main_category, 0) + 1
                            else:
                                # ì¼ë°˜ ë¬¸ìì—´
                                if category_raw.strip():
                                    clean_categories[category_raw] = clean_categories.get(category_raw, 0) + 1
                    except:
                        continue
                
                # ìƒìœ„ 7ê°œ ì§ë¬´ ì„ íƒ
                if clean_categories:
                    sorted_categories = sorted(clean_categories.items(), key=lambda x: x[1], reverse=True)
                    job_role_counts = dict(sorted_categories[:7])
        
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if not job_role_counts:
            job_role_counts = {
                'ë°±ì—”ë“œ': 52,
                'ë¹„ì¦ˆë‹ˆìŠ¤/ê¸°íš': 38,
                'AI/ë¨¸ì‹ ëŸ¬ë‹': 28,
                'PM/PO': 22,
                'ë””ìì¸': 18,
                'DevOps': 15,
                'ë°ì´í„°ë¶„ì„': 12
            }
        
        # ê·¸ë˜í”„ ìƒ‰ìƒ ê°œì„ 
        colors = ['#2563eb', '#06b6d4', '#10b981', '#f59e0b', '#ef4444', '#8b5cf6', '#ec4899']
        
        fig2 = go.Figure()
        fig2.add_trace(go.Bar(
            x=list(job_role_counts.keys()), 
            y=list(job_role_counts.values()),
            marker_color=colors[:len(job_role_counts)],
            text=list(job_role_counts.values()),
            textposition='auto'
        ))
        # ì§ë¬´ë³„ ë¶„í¬ ì´ ê°œìˆ˜ ê³„ì‚°
        job_total = sum(job_role_counts.values()) if job_role_counts else 0
        
        fig2.update_layout(
            title=f'ì§ë¬´ë³„ ì±„ìš©ê³µê³  ë¶„í¬ (ì´ {job_total:,}ê°œ)', 
            height=300, 
            margin=dict(l=20, r=20, t=40, b=20),
            xaxis_title='ì§ë¬´ ë¶„ì•¼',
            yaxis_title='ê³µê³  ìˆ˜',
            showlegend=False,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        charts['job_distribution'] = json.loads(plotly.utils.PlotlyJSONEncoder().encode(fig2))
        
        # 3. ê²½ë ¥ë³„ ë¶„í¬ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜, ì •ë¦¬ëœ ê²½ë ¥ êµ¬ê°„)
        exp_counts = {}
        
        if not data.empty and 'experience_analyzed' in data.columns:
            valid_exp = data[data['experience_analyzed'].notna() & (data['experience_analyzed'] != '') & (data['experience_analyzed'] != 'null')]
            if len(valid_exp) > 0:
                # ê²½ë ¥ ë°ì´í„°ë¥¼ í‘œì¤€ êµ¬ê°„ìœ¼ë¡œ ë¶„ë¥˜
                clean_exp = {
                    'ì‹ ì…': 0,
                    '1-2ë…„': 0,
                    '3-5ë…„': 0,
                    '6-8ë…„': 0,
                    '9ë…„ ì´ìƒ': 0
                }
                
                for exp_raw in valid_exp['experience_analyzed']:
                    exp_str = str(exp_raw).lower()
                    
                    # ìˆ«ì ìš°ì„  ì¶”ì¶œ
                    import re
                    numbers = re.findall(r'\d+', exp_str)
                    
                    # ì‹ ì… ê´€ë ¨
                    if any(keyword in exp_str for keyword in ['ì‹ ì…', '0ë…„', 'ê²½ë ¥ ë¬´ê´€', '0-', '0+', 'ê²½ë ¥ë¬´ê´€']):
                        clean_exp['ì‹ ì…'] += 1
                    # ìˆ«ì ê¸°ë°˜ ë¶„ë¥˜
                    elif numbers:
                        num = int(numbers[0])
                        if num == 0:
                            clean_exp['ì‹ ì…'] += 1
                        elif num <= 2:
                            clean_exp['1-2ë…„'] += 1
                        elif num <= 5:
                            clean_exp['3-5ë…„'] += 1
                        elif num <= 8:
                            clean_exp['6-8ë…„'] += 1
                        else:
                            clean_exp['9ë…„ ì´ìƒ'] += 1
                    # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ (ìˆ«ìê°€ ì—†ëŠ” ê²½ìš°)
                    elif any(keyword in exp_str for keyword in ['1ë…„', '2ë…„', '1-2ë…„', '1+', '2+']):
                        clean_exp['1-2ë…„'] += 1
                    elif any(keyword in exp_str for keyword in ['3ë…„', '4ë…„', '5ë…„', '3-5ë…„', '3+', '4+', '5+']):
                        clean_exp['3-5ë…„'] += 1
                    elif any(keyword in exp_str for keyword in ['6ë…„', '7ë…„', '8ë…„', '6-8ë…„', '6+', '7+', '8+']):
                        clean_exp['6-8ë…„'] += 1
                    elif any(keyword in exp_str for keyword in ['9ë…„', '10ë…„', '12ë…„', '15ë…„', '9+', '10+', '12+', '15+']):
                        clean_exp['9ë…„ ì´ìƒ'] += 1
                    else:
                        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì¤‘ê°„ ê²½ë ¥ìœ¼ë¡œ ë¶„ë¥˜
                        clean_exp['3-5ë…„'] += 1
                
                # ëª¨ë“  í•­ëª© í¬í•¨ (0ê°œì¸ ê²ƒë„ í‘œì‹œ)
                exp_counts = clean_exp
        
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if not exp_counts:
            exp_counts = {
                'ì‹ ì…': 15,
                '1-2ë…„': 28,
                '3-5ë…„': 45,
                '6-8ë…„': 32,
                '9ë…„ ì´ìƒ': 25
            }
        
        fig3 = go.Figure()
        fig3.add_trace(go.Bar(
            x=list(exp_counts.keys()), 
            y=list(exp_counts.values()),
            marker_color='#10b981',
            text=list(exp_counts.values()),
            textposition='auto'
        ))
        # ê²½ë ¥ë³„ ë¶„í¬ ì´ ê°œìˆ˜ ê³„ì‚°
        exp_total = sum(exp_counts.values()) if exp_counts else 0
        
        fig3.update_layout(
            title=f'ê²½ë ¥ë³„ ì±„ìš©ê³µê³  ë¶„í¬ (ì´ {exp_total:,}ê°œ)', 
            height=300, 
            margin=dict(l=20, r=20, t=40, b=20),
            xaxis_title='ê²½ë ¥ êµ¬ê°„',
            yaxis_title='ê³µê³  ìˆ˜',
            showlegend=False,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        charts['experience_distribution'] = json.loads(plotly.utils.PlotlyJSONEncoder().encode(fig3))
        
        # 4. ê·¼ë¬´ í˜•íƒœë³„ ë¶„í¬ (jobs_attributes ê¸°ë°˜)
        work_type_counts = {
            'ì‚¬ë¬´ì‹¤ê·¼ë¬´': 0,
            'í•˜ì´ë¸Œë¦¬ë“œ': 0,
            'ì›ê²©ê·¼ë¬´': 0
        }
        
        if not data.empty:
            # jobs_attributesì—ì„œ ê·¼ë¬´ë°©ì‹ ì •ë³´ í™•ì¸
            for idx, row in data.iterrows():
                jobs_attrs = row.get('jobs_attributes')
                if jobs_attrs and not pd.isna(jobs_attrs):
                    try:
                        if isinstance(jobs_attrs, str):
                            attrs = json.loads(jobs_attrs)
                        else:
                            attrs = jobs_attrs
                        
                        work_style = attrs.get('ê·¼ë¬´ë°©ì‹', '')
                        work_condition = attrs.get('ê·¼ë¬´ì¡°ê±´', '')
                        
                        # ê·¼ë¬´ë°©ì‹ ë¶„ë¥˜
                        combined_text = f"{work_style} {work_condition}".lower()
                        
                        if any(keyword in combined_text for keyword in ['ì›ê²©', 'ì¬íƒ', 'remote', 'ë¦¬ëª¨íŠ¸']):
                            work_type_counts['ì›ê²©ê·¼ë¬´'] += 1
                        elif any(keyword in combined_text for keyword in ['í•˜ì´ë¸Œë¦¬ë“œ', 'hybrid', 'ìœ ì—°', 'ì„ íƒ']):
                            work_type_counts['í•˜ì´ë¸Œë¦¬ë“œ'] += 1
                        else:
                            work_type_counts['ì‚¬ë¬´ì‹¤ê·¼ë¬´'] += 1
                    except:
                        work_type_counts['ì‚¬ë¬´ì‹¤ê·¼ë¬´'] += 1
                else:
                    work_type_counts['ì‚¬ë¬´ì‹¤ê·¼ë¬´'] += 1
        
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        total_work = sum(work_type_counts.values())
        if total_work == 0:
            work_type_counts = {'ì‚¬ë¬´ì‹¤ê·¼ë¬´': 75, 'í•˜ì´ë¸Œë¦¬ë“œ': 20, 'ì›ê²©ê·¼ë¬´': 15}
        
        # 0ì´ ì•„ë‹Œ ê°’ë§Œ í¬í•¨
        work_type_counts = {k: v for k, v in work_type_counts.items() if v > 0}
        
        labels = list(work_type_counts.keys())
        values = list(work_type_counts.values())
        colors = ['#2563eb', '#10b981', '#f59e0b']
        
        fig4 = go.Figure()
        fig4.add_trace(go.Pie(
            labels=labels,
            values=values,
            hole=0.4,
            marker_colors=colors[:len(labels)],
            textinfo='label+percent',
            textposition='auto'
        ))
        # ê·¼ë¬´ í˜•íƒœë³„ ë¶„í¬ ì´ ê°œìˆ˜ ê³„ì‚°
        work_total = sum(values) if values else 0
        
        fig4.update_layout(
            title=f'ê·¼ë¬´ í˜•íƒœë³„ ë¶„í¬ (ì´ {work_total:,}ê°œ)', 
            height=300, 
            margin=dict(l=20, r=20, t=40, b=20),
            showlegend=True,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        charts['remote_work'] = json.loads(plotly.utils.PlotlyJSONEncoder().encode(fig4))
        
        # 5. ê²½ë ¥ë³„ ì—°ë´‰ ë¶„í¬ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
        salary_by_exp = {}
        
        if not data.empty and 'salary_analyzed' in data.columns and 'experience_analyzed' in data.columns:
            # ì—°ë´‰ ë°ì´í„°ê°€ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
            salary_data = data[
                (data['salary_analyzed'].notna()) & 
                (data['salary_analyzed'] != '') & 
                (data['salary_analyzed'] != 'null') &
                (data['experience_analyzed'].notna()) & 
                (data['experience_analyzed'] != '') & 
                (data['experience_analyzed'] != 'null')
            ]
            
            if len(salary_data) > 0:
                # ê²½ë ¥ë³„ í‰ê·  ì—°ë´‰ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ì‹)
                for exp in salary_data['experience_analyzed'].unique():
                    exp_data = salary_data[salary_data['experience_analyzed'] == exp]
                    salaries = []
                    
                    for salary_str in exp_data['salary_analyzed']:
                        try:
                            # ì—°ë´‰ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "$72,700 ~ $176,000" -> í‰ê· ê°’)
                            numbers = re.findall(r'[\d,]+', str(salary_str))
                            if numbers:
                                # ì²« ë²ˆì§¸ ìˆ«ìë¥¼ ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜
                                salary_num = int(numbers[0].replace(',', ''))
                                # USDì¸ ê²½ìš° ì›í™”ë¡œ ëŒ€ëµ ë³€í™˜ (1ë‹¬ëŸ¬=1300ì›)
                                if '$' in str(salary_str):
                                    salary_num = salary_num * 1300 // 10000  # ë§Œì› ë‹¨ìœ„
                                elif salary_num > 10000:  # ì´ë¯¸ ì› ë‹¨ìœ„ì¸ ê²½ìš°
                                    salary_num = salary_num // 10000  # ë§Œì› ë‹¨ìœ„ë¡œ ë³€í™˜
                                salaries.append(salary_num)
                        except:
                            continue
                    
                    if salaries:
                        salary_by_exp[exp] = int(sum(salaries) / len(salaries))
        
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if not salary_by_exp:
            salary_by_exp = {
                'ì‹ ì…': 3500,
                '1-2ë…„': 4200,
                '3-5ë…„': 5500,
                '5ë…„ ì´ìƒ': 7200,
                '8ë…„ ì´ìƒ': 9500,
                '10ë…„+': 12000
            }
        
        # ê²½ë ¥ ìˆœì„œë¡œ ì •ë ¬
        exp_order = ['ì‹ ì…', '1-2ë…„', '2-3ë…„', '3-5ë…„', '5ë…„ ì´ìƒ', '6-10ë…„', '8ë…„ ì´ìƒ', '10ë…„+']
        sorted_salary = {}
        for exp in exp_order:
            if exp in salary_by_exp:
                sorted_salary[exp] = salary_by_exp[exp]
        
        # ë‚¨ì€ ê²½ë ¥ì€ ë’¤ì— ì¶”ê°€
        for exp, salary in salary_by_exp.items():
            if exp not in sorted_salary:
                sorted_salary[exp] = salary
        
        salary_by_exp = sorted_salary
        
        fig5 = go.Figure()
        fig5.add_trace(go.Scatter(
            x=list(salary_by_exp.keys()), 
            y=list(salary_by_exp.values()),
            mode='lines+markers',
            marker=dict(size=12, color='#8b5cf6'),
            line=dict(width=4, color='#8b5cf6'),
            fill='tozeroy',
            fillcolor='rgba(139, 92, 246, 0.1)',
            name='í‰ê·  ì—°ë´‰'
        ))
        # ì—°ë´‰ ë°ì´í„° ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
        salary_sample_count = len(salary_data) if 'salary_data' in locals() and not salary_data.empty else 0
        
        fig5.update_layout(
            title=f'ê²½ë ¥ë³„ í‰ê·  ì—°ë´‰ (ìƒ˜í”Œ {salary_sample_count:,}ê°œ)', 
            height=300, 
            margin=dict(l=20, r=20, t=40, b=20),
            xaxis_title='ê²½ë ¥',
            yaxis_title='ì—°ë´‰ (ë§Œì›)',
            showlegend=False,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        charts['salary_by_experience'] = json.loads(plotly.utils.PlotlyJSONEncoder().encode(fig5))
        
    except Exception as e:
        print(f"ì‹œê°í™” ìƒì„± ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ ì°¨íŠ¸ ìƒì„±
        for chart_name, title in [
            ('monthly_trend', 'ì›”ë³„ ì±„ìš©ê³µê³  ë³€í™”'),
            ('job_distribution', 'ì§ë¬´ë³„ ë¶„í¬'),
            ('experience_distribution', 'ê²½ë ¥ë³„ ë¶„í¬'),
            ('remote_work', 'ì›ê²©ê·¼ë¬´ ë¶„í¬'),
            ('salary_by_experience', 'ê²½ë ¥ë³„ ì—°ë´‰')
        ]:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=[1, 2, 3], y=[10, 20, 15], mode='markers'))
            fig.update_layout(title=title, height=300, margin=dict(l=20, r=20, t=40, b=20))
            charts[chart_name] = json.loads(plotly.utils.PlotlyJSONEncoder().encode(fig))
    
    return charts

def extract_tech_stacks(jobs_attributes):
    """jobs_attributesì—ì„œ ê¸°ìˆ  ìŠ¤íƒ ì •ë³´ ì¶”ì¶œ"""
    try:
        if not jobs_attributes or pd.isna(jobs_attributes):
            return []
        
        # JSON íŒŒì‹±
        if isinstance(jobs_attributes, str):
            attrs = json.loads(jobs_attributes)
        else:
            attrs = jobs_attributes
        
        tech_stacks = []
        
        # ë‹¤ì–‘í•œ í•„ë“œì—ì„œ ê¸°ìˆ  ìŠ¤íƒ í‚¤ì›Œë“œ ê²€ìƒ‰
        search_fields = ['ìê²©ìš”ê±´', 'ìš°ëŒ€ì‚¬í•­', 'ì£¼ìš”ì—…ë¬´', 'ìš”ì•½']
        
        # ì¼ë°˜ì ì¸ ê¸°ìˆ  ìŠ¤íƒ í‚¤ì›Œë“œ
        tech_keywords = {
            # í”„ë¡œê·¸ë˜ë° ì–¸ì–´
            'Python': ['python', 'Python', 'PYTHON'],
            'Java': ['java', 'Java', 'JAVA'],
            'JavaScript': ['javascript', 'JavaScript', 'JS', 'js'],
            'TypeScript': ['typescript', 'TypeScript', 'TS', 'ts'],
            'React': ['react', 'React', 'REACT', 'react.js', 'React.js'],
            'Vue': ['vue', 'Vue', 'vue.js', 'Vue.js'],
            'Angular': ['angular', 'Angular', 'AngularJS'],
            'Node.js': ['node.js', 'Node.js', 'nodejs', 'NodeJS'],
            'Spring': ['spring', 'Spring', 'SpringBoot', 'Spring Boot'],
            'Django': ['django', 'Django'],
            'Flask': ['flask', 'Flask'],
            'Express': ['express', 'Express'],
            'C++': ['c++', 'C++', 'cpp'],
            'C#': ['c#', 'C#', 'csharp'],
            'Go': ['go', 'Go', 'golang', 'Golang'],
            'Kotlin': ['kotlin', 'Kotlin'],
            'Swift': ['swift', 'Swift'],
            'PHP': ['php', 'PHP'],
            'Ruby': ['ruby', 'Ruby', 'rails', 'Rails'],
            # ë°ì´í„°ë² ì´ìŠ¤
            'MySQL': ['mysql', 'MySQL', 'MYSQL'],
            'PostgreSQL': ['postgresql', 'PostgreSQL', 'postgres'],
            'MongoDB': ['mongodb', 'MongoDB', 'mongo'],
            'Redis': ['redis', 'Redis'],
            'Oracle': ['oracle', 'Oracle'],
            'SQL Server': ['sql server', 'SQL Server', 'sqlserver'],
            # í´ë¼ìš°ë“œ/ì¸í”„ë¼
            'AWS': ['aws', 'AWS', 'Amazon Web Services'],
            'Azure': ['azure', 'Azure', 'Microsoft Azure'],
            'GCP': ['gcp', 'GCP', 'Google Cloud'],
            'Docker': ['docker', 'Docker'],
            'Kubernetes': ['kubernetes', 'Kubernetes', 'k8s'],
            'Jenkins': ['jenkins', 'Jenkins'],
            'Git': ['git', 'Git', 'GitHub', 'github'],
            # AI/ML
            'TensorFlow': ['tensorflow', 'TensorFlow'],
            'PyTorch': ['pytorch', 'PyTorch'],
            'Keras': ['keras', 'Keras'],
            'Pandas': ['pandas', 'Pandas'],
            'NumPy': ['numpy', 'NumPy'],
            # ê²Œì„ ì—”ì§„ (ìƒ˜í”Œ ë°ì´í„°ì—ì„œ ë°œê²¬)
            'Unity': ['unity', 'Unity'],
            'Unreal': ['unreal', 'Unreal', 'ì–¸ë¦¬ì–¼'],
            'Niagara': ['niagara', 'Niagara', 'ë‚˜ì´ì•„ê°€ë¼']
        }
        
        # ëª¨ë“  í•„ë“œì—ì„œ ê¸°ìˆ  ìŠ¤íƒ ê²€ìƒ‰
        for field in search_fields:
            if field in attrs and attrs[field]:
                content = str(attrs[field]).lower()
                for tech_name, keywords in tech_keywords.items():
                    if any(keyword.lower() in content for keyword in keywords):
                        if tech_name not in tech_stacks:
                            tech_stacks.append(tech_name)
        
        return tech_stacks[:5]  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
        
    except Exception as e:
        print(f"ê¸°ìˆ  ìŠ¤íƒ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []

def extract_job_link_from_html(job):
    """HTMLì—ì„œ ì±„ìš©ê³µê³  ë§í¬ ì¶”ì¶œ"""
    try:
        html_content = job.get('html', '')
        if not html_content or pd.isna(html_content):
            return None
            
        # ë§í¬ íŒ¨í„´ ì¶”ì¶œ
        patterns = [
            r'href=["\']([^"\']*apply[^"\']*)["\']',
            r'href=["\']([^"\']*job[^"\']*)["\']',
            r'href=["\']([^"\']*career[^"\']*)["\']',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, html_content, re.IGNORECASE)
            for match in matches:
                if match.startswith('http'):
                    return match
        
        # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ íšŒì‚¬ëª…ìœ¼ë¡œ ê²€ìƒ‰ ë§í¬ ìƒì„±
        company = job.get('company', '')
        title = job.get('title', '')
        if company and company != 'N/A':
            search_query = f"{company} {title} ì±„ìš©".replace(' ', '+')
            return f"https://www.google.com/search?q={search_query}"
            
        return None
        
    except Exception as e:
        print(f"ë§í¬ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze_jobs():
    """ì±„ìš©ê³µê³  ë¶„ì„ - ìµœì í™”ëœ ë²„ì „"""
    global curator
    
    if not curator:
        if not initialize_curator():
            return jsonify({'error': 'PostgreSQL ì—°ê²° ì‹¤íŒ¨'}), 500
    
    try:
        # í¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        job_role = request.form.get('job_role', 'ì „ì²´')
        experience = request.form.get('experience', 'ì „ì²´')
        min_salary = request.form.get('min_salary')
        max_salary = request.form.get('max_salary')
        company_type = request.form.get('company_type', 'ì „ì²´')
        
        print(f"ğŸ“Š ë¶„ì„ ìš”ì²­: ì§ë¬´={job_role}, ê²½ë ¥={experience}, ì—°ë´‰={min_salary}~{max_salary}, íšŒì‚¬ìœ í˜•={company_type}")
        print(f"ğŸ” ì›ë³¸ í¼ ë°ì´í„°: {dict(request.form)}")
        
        # í•„í„° ì¡°ê±´ êµ¬ì„±
        filters = {}
        print(f"ğŸ” ë°›ì€ íŒŒë¼ë¯¸í„°: job_role={job_role}, experience={experience}, company_type={company_type}")
        
        if job_role != 'ì „ì²´':
            filters['job_role'] = job_role
        if experience != 'ì „ì²´':
            filters['experience'] = experience
        if min_salary:
            try:
                filters['min_salary'] = float(min_salary)
            except ValueError:
                pass
        if max_salary:
            try:
                filters['max_salary'] = float(max_salary)
            except ValueError:
                pass
        if company_type != 'ì „ì²´':
            filters['company_type'] = company_type
        
        print(f"ğŸ” êµ¬ì„±ëœ í•„í„°: {filters}")
        
        # ì´ ê°œìˆ˜ ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜ìš©)
        total_count = curator.get_jobs_count(table_name="jobs", filters=filters)
        
        if total_count == 0:
            print(f"âŒ í•„í„° ì¡°ê±´: {filters}")
            print(f"âŒ ì´ ê°œìˆ˜ê°€ 0ì…ë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return jsonify({'error': 'ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        print(f"ğŸ” í•„í„°ë§ëœ ë°ì´í„°: ì´ {total_count}ê°œ")
        
        # ì„¸ì…˜ì— í•„í„° ì •ë³´ ì €ì¥ (í˜ì´ì§€ë„¤ì´ì…˜ ì‹œ ì‚¬ìš©)
        session['current_filters'] = filters
        session['total_count'] = total_count
        
        # ì²« í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        return jsonify({
            'success': True,
            'total_jobs': total_count,
            'redirect': '/jobs?page=1'
        })
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/jobs')
def show_jobs():
    """ì±„ìš©ê³µê³  ëª©ë¡ í‘œì‹œ (ìµœì í™”ëœ í˜ì´ì§€ë„¤ì´ì…˜)"""
    global curator
    
    if not curator:
        if not initialize_curator():
            return render_template('jobs.html', 
                                 jobs=[], 
                                 page=1, 
                                 total_pages=0, 
                                 total_jobs=0,
                                 error="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
    
    # í˜ì´ì§€ë„¤ì´ì…˜ íŒŒë¼ë¯¸í„°
    page = request.args.get('page', 1, type=int)
    per_page = 12  # í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜
    
    # ì„¸ì…˜ì—ì„œ í•„í„° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    filters = session.get('current_filters', {})
    total_count = session.get('total_count', 0)
    
    if total_count == 0:
        return render_template('jobs.html', 
                             jobs=[], 
                             page=1, 
                             total_pages=0, 
                             total_jobs=0,
                             error="ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    total_pages = (total_count + per_page - 1) // per_page
    
    # í˜ì´ì§€ ë²”ìœ„ ê²€ì¦
    if page < 1:
        page = 1
    elif page > total_pages:
        page = total_pages
    
    # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° DBì—ì„œ ì§ì ‘ ì¡°íšŒ
    offset = (page - 1) * per_page
    page_data = curator.get_jobs_data(
        table_name="jobs",
        limit=per_page,
        offset=offset,
        filters=filters
    )
    
    if page_data.empty:
        return render_template('jobs.html', 
                             jobs=[], 
                             page=page, 
                             total_pages=total_pages, 
                             total_jobs=total_count,
                             error="í•´ë‹¹ í˜ì´ì§€ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë°ì´í„°í”„ë ˆì„ì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    jobs_list = []
    
    for idx, (_, job) in enumerate(page_data.iterrows()):
        # ìš°ì„  url ì»¬ëŸ¼ ì‚¬ìš©
        job_link = job.get('url', None)
        
        # urlì´ ì—†ìœ¼ë©´ HTMLì—ì„œ ì¶”ì¶œ ì‹œë„
        if not job_link or pd.isna(job_link):
            job_link = extract_job_link_from_html(job) if 'html' in job.index else None
            
        # ë§í¬ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        if not job_link or pd.isna(job_link):
            job_link = '#'
        
        # jobs_attributesì—ì„œ ê¸°ìˆ  ìŠ¤íƒ ì¶”ì¶œ
        tech_stacks = extract_tech_stacks(job.get('jobs_attributes'))
        
        # ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
        attrs = {}
        if job.get('jobs_attributes') and not pd.isna(job.get('jobs_attributes')):
            try:
                if isinstance(job['jobs_attributes'], str):
                    attrs = json.loads(job['jobs_attributes'])
                else:
                    attrs = job['jobs_attributes']
            except Exception as e:
                attrs = {}
        
        # ë³µë¦¬í›„ìƒ ì •ë³´ ì¶”ì¶œ
        benefits = []
        if attrs.get('ë³µë¦¬í›„ìƒ'):
            benefits_text = str(attrs['ë³µë¦¬í›„ìƒ'])
            # ê°„ë‹¨í•œ ë³µë¦¬í›„ìƒ í‚¤ì›Œë“œ ì¶”ì¶œ
            benefit_keywords = ['ì—°ì°¨', 'íœ´ê°€', 'ë³´í—˜', 'êµìœ¡ë¹„', 'ê°„ì‹', 'ì ì‹¬', 'ì•¼ì‹', 'íœ´ê²Œì‹¤', 'ì¹´í˜', 'í—¬ìŠ¤ì¥', 'ë„ì„œêµ¬ì…ë¹„', 'ì„±ê³¼ê¸‰', 'ìŠ¤í†¡ì˜µì…˜']
            for keyword in benefit_keywords:
                if keyword in benefits_text:
                    benefits.append(keyword)
        
        job_dict = {
            'id': offset + idx + 1,
            'company': job.get('company', 'N/A'),
            'title': job.get('title', 'N/A'),
            'job_role': job.get('job_role_analyzed', job.get('major_category', job.get('position', ''))),
            'experience': job.get('experience_analyzed', ''),
            'location': job.get('location_analyzed', job.get('category', '')),
            'salary': job.get('salary_analyzed', ''),
            'tech_stacks': tech_stacks,
            'link': job_link,
            'url': job.get('url', '#'),
            'benefits': benefits[:3],  # ìµœëŒ€ 3ê°œ ë³µë¦¬í›„ìƒ
            'employment_type': attrs.get('ê³ ìš©í˜•íƒœ', ''),
            'education': attrs.get('ìš”êµ¬í•™ë ¥', ''),
            'work_type': attrs.get('ê·¼ë¬´ë°©ì‹', ''),
            'deadline': attrs.get('ì§€ì›ë§ˆê°ì¼', '')
        }
        jobs_list.append(job_dict)
    
    # ì‹œê°í™” ë°ì´í„° ìƒì„± (ì²« í˜ì´ì§€ì—ì„œë§Œ)
    charts = None
    if page == 1:
        charts = generate_visualization_data(page_data)
    
    return render_template('jobs.html',
                         jobs=jobs_list,
                         page=page,
                         total_pages=total_pages,
                         total_jobs=total_count,
                         start_idx=offset + 1,
                         end_idx=min(offset + per_page, total_count),
                         per_page=per_page,
                         charts=charts)

if __name__ == '__main__':
    print("Flask ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘...")
    print("http://localhost:5008 ì—ì„œ ì ‘ì† ê°€ëŠ¥")
    app.run(debug=True, host='0.0.0.0', port=5008)